{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog.  \n",
    "Step 1: Gathering data<br>\n",
    "Step 2: Assessing data<br>\n",
    "Step 3: Cleaning data<br>\n",
    "Step 4: Storing data<br>\n",
    "Step 5: Analyzing, and visualizing data<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Gathering data<br>\n",
    "* Download this file manually by clicking the following link: **twitter_archive_enhanced.csv**\n",
    "* File **image_predictions.tsv** is present in each tweet according to a neural network. It is hosted on Udacity's servers and should be downloaded programmatically using the Requests \n",
    "* Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called **tweet_json.txt** file.<br>\n",
    "\n",
    "Step 2: Assessing data\n",
    "* Explore **twitter_archive_enhanced.csv**\n",
    "* Explore **image_predictions.tsv**\n",
    "* Explore **tweet_json.txt**\n",
    "* Display, length, info, missing data, check duplicate tweet_id, type column,...\n",
    "* The columns is type number required > 0.\n",
    "* Data tidiness\n",
    "* Define the problems to be solved at the clean data step.\n",
    "\n",
    "Step 3: Cleaning data<br>\n",
    "* Coppy Dataframe to df_clean\n",
    "* Solved the problems define above.\n",
    "* Eliminate the columns have a lot value null will not use in DataFrame\n",
    "* Convert type the columns have issue type\n",
    "* Delete record have value doesn't make sense mathematically\n",
    "* Order by data by column.\n",
    "* Define the columns will use.\n",
    "* Display DataFrame after clean.\n",
    "\n",
    "Step 4: Storing data<br>\n",
    "* Perform join 3 DataFrame and select column necessary\n",
    "* Save gathered, assessed, and cleaned master dataset to a CSV file named **\"twitter_archive_master.csv\"**.\n",
    "\n",
    "Step 5: Analyzing, and visualizing data\n",
    "* Defines what analysis to do on this final dataset\n",
    "1. Favorite and reetweet of four stage dog: doggo-floofer-pupper-puppo\n",
    "2. The rating rate on a 10 scale: rating_numerator/rating_denominator\n",
    "3. Time frame for users to use tweets in dataset\n",
    "* Analysis and Visualization(chart) for 3 analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is quite interesting when students want to analyze and visualize the dogs.<br>\n",
    "So to have an attractive analysis and evaluation for this data set requires quite a lot of ideas.<br>\n",
    "In general, the data is still quite messy, there is still a lot of blank, meaningless data.<br>\n",
    "**Limit:**<br>\n",
    "1. Dataset twitter_archive_enhanced.csv:<br>\n",
    "The data must be NaN instead of None.<br>\n",
    "2. The image_predictions.tsv dataset:<br>\n",
    "From my point of view it doesn't make any sense, because all 3 dog breed prediction algorithms are not the same -> confounding data.<br>\n",
    "3. The tweet_json.txt dataset after call to the tweet API:<br>\n",
    "There are columns that don't make sense because all values are null<br>\n",
    "There is no document describing the meaning of the columns<br>\n",
    "Nested data type json in columns -> messy data.<br>\n",
    "\n",
    "**Conclusion:**<br>\n",
    "Several factors can be analyzed from the above data.<br>\n",
    "The stage of the favorite dog<br>\n",
    "Number of likes and reviews<br>\n",
    "Timeframe in which users use tweets in dataset<br>\n",
    "Know how to call API from tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
